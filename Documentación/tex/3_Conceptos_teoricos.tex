\capitulo{3}{Conceptos teóricos}

% En aquellos proyectos que necesiten para su comprensión y desarrollo de unos conceptos teóricos de una determinada materia o de un determinado dominio de conocimiento, debe existir un apartado que sintetice dichos conceptos.

\section{Minería de datos}\label{DefMineria}

Es el proceso mediante el cual podemos extraer conocimiento de un conjunto de datos que, sin ser tratados o analizados previamente, no nos proporcionan información útil \cite{DataMiningConcepts}. \\

Se trata de un término que a menudo puede generar confusión con el de KDD (Knowledge Discovery from Data), siendo en ocasiones tratado como un mero sinónimo de este término (que apareció antes que el de minería de datos) y en otras siendo descrito como un mero proceso dentro del descubrimiento de información, encargado de obtener conocimiento mediante la aplicación de algoritmos sobre datos recibidos~\cite{DataMiningConcepts}. 

KDD puede ser definido como una serie de pasos cuyo objetivo final es la extracción de información de un gran conjunto de datos~\cite{DataMiningConcepts}. Podemos agrupar dichos pasos en tres grandes fases: obtención y pre procesamiento de la información, aplicación de algoritmos de minería de datos y análisis y presentación de los resultados.

A lo largo de esta memoria trataremos a la minería de datos como sinónimo de KDD, esto es, el conjunto de procesos que comprenden desde el pre procesamiento de los datos hasta la obtención final de información útil.


\section{Algoritmos de selección de instancias}\label{sec:DefAlgSel}

El objetivo de estos algoritmos es solucionar dos problemas que afectan a la minería de datos: la cantidad cada vez mayor de datos, y su calidad. Podremos, por lo tanto,  definirlos como una herramienta para extraer, de un conjunto de instancias, aquellas que conocemos, o sospechamos, son superfluas o perjudiciales~\cite{IntroInstanceSelect}.

Eliminando una porción del conjunto de instancias durante la fase de pre procesamiento de los datos conseguimos que el tiempo de ejecución algoritmos posteriores se reduzca, dado que hay menos instancias a examinar, mientras que es posible mejorar los resultados obtenidos al finalizar el proceso de minería~\cite{IntroInstanceSelect}.

Podemos clasificar estos algoritmos de acuerdo al tipo de instancias que eliminemos ~\cite{Garcia2012}. Así pues, podemos distinguir entre:

\begin{itemize}
	\item \textbf{Algoritmos de condensación:} Se concentra en mantener las instancias cercanas a las fronteras de decisión entre las clases.
	\item \textbf{Algoritmos de edición:} Eliminan instancias ruidosas así como aquellas que se encuentran muy cerca de la frontera de decisión, intentando mejorar la calidad del conjunto y produciendo una frontera entre clases mucho más suave.
	\item \textbf{Algoritmos híbridos:} Intentan encontrar el subconjunto de instancias más pequeño posible que mantenga o incluso mejore el resultado que más tarde conseguirá el algoritmo de minería de datos que apliquemos. Para ello permite eliminar cualquier tipo de instancias. 
\end{itemize}

De la misma manera, según la forma en la que se construya el nuevo conjunto de datos podemos diferenciar entre las siguientes clases de algoritmos~\cite{Garcia2011}:

\begin{itemize}
	\item \textbf{De incremento:} Partimos de un conjunto vacío o con unas pocas instancias significativas y añadimos nuevas instancias con cada iteración del algoritmo.
	\item \textbf{De decremento:} Comenzamos con todas las instancias y mediante operaciones de eliminación conseguimos un nuevo conjunto de tamaño menor.
	\item \textbf{Fijos:} Desde el principio el usuario indica el número final de instancias al que queremos reducir un conjunto. Son algoritmos muy dependientes del conjunto de datos utilizado. 
	\item \textbf{Mixto:} Comenzamos con un subconjunto de instancias, obtenidas de manera aleatoria o tras aplicar otro algoritmo de selección, y realizamos operaciones para añadir o eliminar instancias de ese dicho conjunto.
\end{itemize}


\section{Computación paralela}\label{sec:CompParalela}

La computación paralela es un tipo de computación en la que múltiples operaciones son llevadas a cabo simultáneamente \cite{Almasi:1989}. Parte del principio de que algunos problemas pueden subdividirse en problemas independientes más pequeños que pueden resolverse al mismo tiempo.

Es un paradigma que desde el principio se usó para operaciones que requiriesen una gran carga computacional, pero que ha despertado mucho interés en los últimos años gracias a la fácil escalabilidad (ver \nameref{sec:Escalabilidad}) que puede ofrecer frente a otras alternativas, como el aumento de la frecuencia de los procesadores, que han alcanzado un punto donde resulta más difícil avanzar \cite{CompParalelaWiki}.

En lo que se refiere al uso de la memoria por parte de un sistema paralelo, existe la posibilidad de que la memoria sea compartida o distribuida dependiendo de si las unidades de procesamiento poseen un espacio de memoria común o cada unidad posee su propio espacio. En cuanto a la tecnología que vamos a usar durante la realización del proyecto (ver \nameref{sec:DefSpark}) la memoria siempre será distribuida \cite{SparkPaper}.

\section{Escalabilidad}\label{sec:DefEscalabilidad}

Escalabilidad es la capacidad de un sistema para adaptarse y soportar una carga de trabajo cada vez mayor~\cite{Bondi:2000}.

En función de la manera de adaptarse a la nueva cantidad de trabajo, podemos diferenciar entre la escalabilidad horizontal, cuando añadimos más nodos a nuestro sistema, y vertical, cuando mejoramos las prestaciones de los elementos ya existentes~\cite{EscalabilidadWiki}. Durante el desarrollo de la memoria siempre usaremos el término de escalabilidad para referirnos a la escalabilidad horizontal, pues estaremos hablando de sistemas distribuidos.

También es una característica que puede aplicarse a los algoritmos, para los cuales definimos escalabilidad como la capacidad de funcionar eficientemente cuando se aplican sobre situaciones que requieran una gran carga de trabajo. En lo referente al proyecto, esa situación será, por lo general, tratar con grandes conjuntos de datos.


\todo{Mencionar en algún lugar eficiencia y meter la ISO9126 de por medio}

\todo{Posibles secciones a explicar: Map Reduce o Big Data}


%=================================================================
%POSIBLES SECCIONES
%=================================================================

\begin{comment}
\subsection{Big Data}

\subsection{MapReduce}

MapReduce se especializó demasiado y se volvió muy complicado, por lo que nació Spark(de la conferencia)

Viene bastante en las diapositivas \href{http://training.databricks.com/workshop/itas_workshop.pdf}{enlace}

Papel del mapreduce: \href{http://research.google.com/archive/mapreduce.html}{enlace}

\end{comment}



