\capitulo{4}{Técnicas y herramientas}

%Esta parte de la memoria tiene como objetivo presentar las técnicas metodológicas y las herramientas de desarrollo que se han utilizado para llevar a cabo el proyecto. Si se han estudiado diferentes alternativas de metodologías, herramientas, bibliotecas se puede hacer un resumen de los aspectos más destacados de cada alternativa, incluyendo comparativas entre las distintas opciones y una justificación de las elecciones realizadas. 
%No se pretende que este apartado se convierta en un capítulo de un libro dedicado a cada una de las alternativas, sino comentar los aspectos más destacados de cada opción, con un repaso somero a los fundamentos esenciales y referencias bibliográficas para que el lector pueda ampliar su conocimiento sobre el tema.

\section{Técnicas}
\subsection{Scrum}

Scrum es una metodología ágil de desarrollo iterativo e incremental para la gestión del desarrollo de un producto. \cite{wikiScrum} 

Como parte de la metodología, el trabajo se ha dividido en springs, intervalos de tiempo de pocas semanas que ofrecen un producto al final de los mismos, que a su vez se han dividido en hitos y estos en tareas.

En lo que se refiere a su aplicación práctica dentro del proyecto, los springs han tenido una duración aproximada de dos semanas, periodo tras el cual había una reunión entre alumno y tutores para hablar sobre el avance y problemas ocurridos a lo largo del spring, así como para definir el avance del proyecto durante el próximo periodo de tiempo.

Para la gestión de los hitos y tareas nos hemos apoyado en el gestor de incidencias que la plataforma Bitbucket (ver \nameref{DefBitbucket}) proporciona en el repositorio del proyecto. De esta manera, cada incidencia marcada con la etiqueta \textit{task} corresponde con una tarea a realizar, mientras que todas ellas están agrupadas en hitos, llamados \textit{milestones} en la plataforma.

\section{Herramientas}

\subsection{Apache Spark}\label{sec:DefSpark}

Apache Spark es un motor de interés general destinado al procesamiento distribuido de grandes conjuntos de datos. Está implementado en Scala, pero también proporciona APIs para otros lenguajes de programación (Java, Python y R) y otro tipo de herramientas para áreas como el aprendizaje automático (ver la sección \nameref{MLib}) \cite{SparkDoc}.

La idea nació como proyecto en 2010, en la Universidad de California, Berkeley, y su primera versión estable apareció el 30 de mayo de 2014. La motivación inicial era la de proporcionar un nuevo modelo de computación paralela que permitiera la ejecución eficiente de modelos que debían utilizar durante múltiples iteraciones grandes conjuntos de datos. Aproximaciones anteriores basadas en el modelo de MapReduce (como Hadoop), requerían cargar de nuevo todos los datos en memoria, haciendo la tarea demasiado costosa\cite{SparkPaper}. Como beneficio adicional, Spark ha demostrado que requiere de muchas menos líneas de código a la hora de programar algoritmos destinados al manejo de \textit{Big Data}.

\todo{Comentario: Cita de MapReduce y Hadoop.}
Actualmente Spark es un proyecto de código abierto cedido a Apache, siendo uno de los más activos en cuanto a contribuciones de la comunidad \cite{ApacheContributions}. 

Para la realización del proyecto utilizaremos la versión de Spark 1.5.0.

\subsubsection{Machine Learning Library (MLlib)}\label{MLib}

Se trata de una de las librerías incluidas en Spark. Contiene un conjunto de algoritmos de aprendizaje automático y algunas herramientas para ayudar en las labores de minería de datos, como tipos de datos o herramientas estadísticas.  

\subsection{Apache Hadoop}
Es un framework escrito en Java destinado a el procesamiento distribuido de datos, tal y como hemos definido a Spark en la sección  \nameref{sec:DefSpark}. Al igual que Apache Spark, se trata de un proyecto de código abierto \cite{HadoopPage}.


Nació en 2006 de la mano de \textit{Yahoo!}, quien más tarde lo cedería a Apache, como un proyecto que aplicase el modelo de programación de MapReduce que cuatro años atrás había definido Google \cite{DatabricksSlides}. Esta es la principal diferencia con Spark, quien ha dejado atrás el modelo anteriormente citado y ha seguido un nuevo camino gracias a las estructuras RDD.

Aunque Hadoop no ha sido utilizado directamente, se ha requerido de su instalación para el correcto funcionamiento de Spark. Aunque teóricamente ambos sistemas son independientes, existen en Spark algunas referencias a clases de Hadoop que pueden dar lugar a errores en el desarrollo de no encontrarse, razón por la que se ha decidido instalar.

La versión instalada es Hadoop 2.6.0.

\subsection{Scala}
Scala es un lenguaje de programación orientado a objetos y a la programación funcional y fuertemente tipado.

Es un lenguaje compilado, produciendo como salida ficheros .class que han de ser ejecutados en una máquina virtual de Java (JVM). Esto permite que librerías de Java puedan ser utilizadas directamente en Scala y viceversa. Por la misma razón, Scala posee la misma portabilidad que Java, pudiendo ejecutarse en cualquier sistema operativo siempre y cuando cuente con una máquina virtual de Java. 

Los motivos de su elección como lenguaje de programación han sido mencionados anteriormente en la sección \nameref{EleccionLenguaje}

Se ha usado Scala en su versión 2.11.7.

\subsection{Java}

Java es un lenguaje de programación orientado a objetos de propósito general diseñado para producir programas multiplataforma.

Necesitamos realizar la instalación de Java porque, aunque no trabajemos directamente sobre este lenguaje, si vamos a necesitar de su máquina virtual para poder ejecutar nuestros programas.

Hemos usado Java 8 u60 para la realización del proyecto.

\subsubsection{JConsole}\label{DefJConsole}

JConsole es una herramienta gráfica de monitorización para aplicaciones Java locales o remotas. Es una herramienta incluida dentro del Java Development Kit (JDK).

En el proyecto, se ha utilizado para evaluar y medir el rendimiento de aplicaciones en Java a nivel local.

La elección de utilizar esta herramienta frente a cualquier otra ha sido su facilidad de uso y la posibilidad de poder exportar a CSV las mediciones realizadas sobre el uso de memoria o CPU. Además, existe el hecho de que es una herramienta ya incluida en el JDK de Java.



\subsubsection{JvisualVM}\label{DefJvisualVM}
JvisualVM es una herramienta que proporciona información detallada sobre las aplicaciones Java que están corriendo en el sistema.

Su funcionalidad es practicamente similar a la de JConsole (ver \nameref(JConsole)), sin embargo, ofrece una mejor información sobre el estado de los hilos que componen una aplicación Java, siendo este el uso que se le ha dado a la aplicación.

\subsection{Bitbucket}\label{DefBitbucket}
Es un repositorio de código que permite la creación, control y mantenimiento de proyectos, que podrán ser públicos o privados. Aunque Bitbucket ofrece la posibilidad de usarlo gratuitamente, también cuenta con otras posibilidades que solo se encontrarán disponibles en su versión de pago, como poseer un proyecto con un número ilimitado de colaboradores.

Puede trabajar con los sistemas de control de versiones Git y Mercurial.

Bitbucket fue propuesto como gestor del proyecto durante el primer spring del proyecto y, al no tener preferencia por ningún otro repositorio, se aceptó como herramienta a utilizar.

\subsubsection{Git}

Git es un sistema de control de versiones gratuito y de código abierto.

La elección de Git vino motivada por ser un sistema que ya había sido utilizado antes a lo largo de la carrera, por lo que no ha sido necesario aprender su funcionamiento.

Se ha utilizado la versión 2.6.2.


\subsection{Eclipse}
Eclipse es un entorno de desarrollo integrado (IDE de sus siglas en inglés) gratuito y de código abierto. Aunque su principal uso se basa en el desarrollo de aplicaciones en Java, también puede ser adaptado mediante el uso de plugins para ser utilizado en el desarrollo de otros lenguajes.

Como muchos otros entornos de desarrollo, posee como herramienta principal un editor de texto que en el caso de Eclipse cuenta con diferentes funcionalidades que pretenden apoyar al programador, poniendo como ejemplo el resaltado de texto, el autocompletado o la notificación y posibles soluciones de errores.

Un dato importante de este entorno de desarrollo es que está puramente basado en plugins, esto es, a excepción de un pequeño kernel, cualquier otra funcionalidad está incluida como un plugin, lo que le proporciona una gran facilidad para ser escalado o adaptado a las necesidades del usuario concreto.

Hemos trabajado sobre Eclipse 4.4.2.

\subsection{ScalaIDE for Eclipse}

Se trata de un plugin que puede añadirse al entorno de desarrollo Eclipse para poder desarrollar en Scala desde Eclipse.
Este plugin consigue imitar la mayoría de los aspectos que Eclipse proporciona para Java para permitir un desarrollo más cómodo, esto es, el autocompletado de código, resaltado de texto, definiciones e hipervínculos a clases, marcadores de errores y opción \textit{debug}

La versión utilizada de este plugin es la 4.2.0.


\subsection{Weka}\label{sec:DefWeka}
Weka es un software desarrollado para llevar a cabo labores de minería de datos. Se trata de un proyecto de software libre, realizado en Java y desarrollado por la Universidad de Waikato, Nueva Zelanda.

Contiene, no solo algoritmos de aprendizaje automático para la minería de datos, sino también algoritmos de pre procesamiento de los datos o de visualización.

Al contrario que otras tecnologías que vamos a usar, esta librería no está pensada para la ejecución en paralelo, lo que la convierte en una buena herramienta para comparar el rendimiento que aplicaciones como Spark (véase \nameref{DefSpark}) pueden ofrecernos.

Se ha usado en su versión 3.6.13.


%Si lo queremos citar algo dicen que lo hagamos tal que  
%Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, Ian H. Witten (2009); The WEKA Data Mining Software: An Update; SIGKDD Explorations, Volume 11, Issue 1. 


\subsection{Zotero}
Zotero es un gestor de referencias bibliográficas gratuito. Esta herramienta permite almacenar, de manera sencilla, referencias a un recurso concreto, permitiendo además crear una estructura de carpetas para clasificar las referencias o hasta compartir una biblioteca de referencias con otros usuarios registrados en el servicio.

La función de esta aplicación ha sido la de recompilar y organizar todos los enlaces que pudiesen ser de interés para la realización del trabajo y la memoria.

Para su uso se ha utilizado el plugin para el navegador Mozilla Firefox en su versión 4.0.

\subsection{TeX Live}
TeX Live es una distribución gratuita de LaTeX creada en 1996 y mantenida actualizada hasta la fecha. LaTeX, por su parte, es un sistema de creación documentos en los que se requiera una alta calidad tipográfica.

En el proyecto se ha utilizado LaTeX para la realización de la memoria, así como los documentos anexos.

TeX Live la distribución por defecto en muchos sistemas operativos Linux. Se ha utilizado su versión más reciente hasta la fecha, TeX Live 2015.

\subsection{TexMaker}

TexMaker es un editor multiplataforma pensado para el desarrollo de documentos escritos en LaTex. Al igual que otros muchos editores, esta plataforma presenta diferentes herramientas para hacer la creación de los documentos mucho más sencilla, tales como el autocompletado de etiquetas, la detección de errores ortográficos o el coloreado de texto.

Hemos usado la versión 4.4.1.

\subsection{ProjectLibre}
ProjectLibre es un programa de gestión de proyectos nacido como alternativa de código abierto a otros programas como Microsoft Project.

Está pensado para ayudar en el desarrollo de un plan de proyecto, en el seguimiento de dicho plan o en la gestión de recursos y cargas de trabajo.

En este proyecto ha sido utilizado para documentar el avance del mismo a lo largo del semestre. 


\todo{A incluir: Maven}


